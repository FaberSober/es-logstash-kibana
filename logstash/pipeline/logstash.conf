input {
  stdin {
  }
  jdbc {
    # mysql数据库连接
    jdbc_connection_string => "jdbc:mysql://127.0.0.1:3306/db?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC"
    # mysqly用户名和密码
    jdbc_user => "root"
    jdbc_password => "123456"
    # 驱动配置
    jdbc_driver_library => "/usr/share/logstash/mysql-connector-java-8.0.27.jar"
    # 驱动类名
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    codec => plain { charset => "UTF-8"}

    tracking_column => update_time

    #上一次执行到的追踪字段的值存放路径 手动创建
    last_run_metadata_path => "/usr/share/logstash/pipeline/logstash_jdbc_last_run"
    # 执行指定的sql文件
    #statement_filepath => "D:\service\logstash-7.7.0\mysql\sql\med_article.sql"

    #执行的sql语句
    statement => "SELECT * FROM article"

    clean_run => false
    # 设置监听 各字段含义 分 时 天 月  年 ，默认全部为*代表含义：每分钟都更新
    schedule => "*/1 * * * *"
    # 索引类型
    #type => "blog"
  }
}

# 添加过滤器
filter {
  mutate {
    # 过滤content字段的html标签
    gsub => [
      "content", "<.*?>", ""
    ]
    # 过滤content字段的&nbsp;标签
    gsub => [
      "content", "&nbsp;", ""
    ]
  }
}

output {
   elasticsearch {
    #es服务器
    hosts => ["es01:9200"]
    #ES索引名称
    index => "article"
    #自增ID
    document_id => "%{id}"
  }

  stdout {
    codec => json_lines
  }
}